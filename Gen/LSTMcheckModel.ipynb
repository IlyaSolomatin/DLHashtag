{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "#from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop, Adadelta, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('corpus length:', 896291)\n",
      "('total chars:', 40)\n"
     ]
    }
   ],
   "source": [
    "text = open('datasetV2twplustag').read().lower()#open('BigData').read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('datasetV2twplustag') as f: #open('BigData') as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "f = [x.strip().lower() for x in content] \n",
    "\n",
    "end = []\n",
    "vri = []\n",
    "for i in range(len(content)):\n",
    "    end.append(content[i].index('['))\n",
    "    vri.append(content[i].index(']')-content[i].index('[')+1)\n",
    "    content[i] = content[i][:-1].lower()\n",
    "    \n",
    "sentences = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128049, 144, 40)\n"
     ]
    }
   ],
   "source": [
    "maxlen = len(max(content, key=len))\n",
    "\n",
    "X = np.zeros((sum(vri), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((sum(vri), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    k = sum(vri[:i])-i\n",
    "    for j in range(1, vri[i]):\n",
    "        for t, char in enumerate(sentence[:-j]):\n",
    "            X[k+j-1, t+(maxlen-len(sentence[:-j])), char_indices[char]] = 1\n",
    "        y[k+j-1, char_indices[sentence[-j]]] = 1\n",
    "\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float32')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    choices = range(len(preds))##new\n",
    "    \n",
    "    #probas = np.random.multinomial(1, preds, 1)\n",
    "    \n",
    "    return np.random.choice(choices, p=preds) #np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('modelKsmall155')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('diversity:', 0.2)\n",
      "real hashtag: [mufc]\n",
      "generated hashtag: []\n",
      "\n",
      "('diversity:', 0.5)\n",
      "real hashtag: [mufc]\n",
      "generated hashtag: [sr]\n",
      "\n",
      "('diversity:', 1.0)\n",
      "real hashtag: [mufc]\n",
      "generated hashtag: [in]\n",
      "\n",
      "('diversity:', 1.3)\n",
      "real hashtag: [mufc]\n",
      "generated hashtag: [fo2]\n",
      "\n",
      "('diversity:', 1.5)\n",
      "real hashtag: [mufc]\n",
      "generated hashtag: [f92]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tn = 2\n",
    "for diversity in [0.2, 0.5, 1.0, 1.3, 1.5]:\n",
    "    print('diversity:', diversity)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = content[tn][:end[tn]+1]#text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    generated += '['\n",
    "    #print 'Generating with seed:\\n\"' + sentence[:] +'\"'\n",
    "    print 'real hashtag: ' + content[tn][end[tn]:]\n",
    "    #print 'generated hashtag: ['\n",
    "    #sys.stdout.write(generated+'\\n[')\n",
    "    sys.stdout.write('generated hashtag: [')\n",
    "    \n",
    "    for i in range(400):\n",
    "        x = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        if (next_char==']'):\n",
    "            break\n",
    "        \n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a,b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t real [coyr] \t generated: [vlhan]\n",
      "\t real [coyr] \t generated: [sbpuit]\n",
      "\t real [coyr] \t generated: []\n",
      "\t real [mufc] \t generated: [ordhnry]\n",
      "\t real [mufc] \t generated: [van2w]\n",
      "\t real [mufc] \t generated: [eaenm]\n",
      "\t real [mufc] \t generated: [rweow]\n",
      "\t real [mufc] \t generated: [bxmfymfo1ynnepacboxrip1yevaattpbgenns2nurmsiuiicltmwwdk]\n",
      "\t real [mufc] \t generated: [e2hh]\n",
      "\t real [master] \t generated: []\n",
      "\t real [master] \t generated: [dvt2lglpzrmeyprn2sa]\n",
      "\t real [master] \t generated: [s]\n",
      "\t real [fcb] \t generated: [wtctn]\n",
      "\t real [fcb] \t generated: [ociflobytqf11rtl]\n",
      "\t real [fcb] \t generated: [usttnpd]\n",
      "\t real [chimeforchange] \t generated: []\n",
      "\t real [chimeforchange] \t generated: [epysiiidizdcpesv]\n",
      "\t real [chimeforchange] \t generated: [7]\n",
      "\t real [dataviz] \t generated: [o]\n",
      "\t real [dataviz] \t generated: [l]\n",
      "\t real [dataviz] \t generated: [koc]\n",
      "\t real [vr] \t generated: [dop]\n",
      "\t real [vr] \t generated: [sso]\n",
      "\t real [vr] \t generated: [ebfgazlmlt0t5yyly]\n",
      "\t real [worldmalariaday] \t generated: [s]\n",
      "\t real [worldmalariaday] \t generated: [tasjcrrlsyo]\n",
      "\t real [worldmalariaday] \t generated: [tpdbhisj2cznedfcntj]\n",
      "\t real [bigdebate] \t generated: [sst]\n",
      "\t real [bigdebate] \t generated: [hfyigteuagttia1t4]\n",
      "\t real [bigdebate] \t generated: [iyqfooestahbdhdfolgmdo2i]\n",
      "\t real [ukaid] \t generated: [iaeehpsgedoi4mumttenwtx]\n",
      "\t real [ukaid] \t generated: [aoja2aif]\n",
      "\t real [ukaid] \t generated: [wevm1eftwsd5b]\n",
      "\t real [vr] \t generated: []\n",
      "\t real [vr] \t generated: []\n",
      "\t real [vr] \t generated: [twna]\n",
      "\t real [gearvr] \t generated: [1roitnegr]\n",
      "\t real [gearvr] \t generated: [pbplprofbbt1a]\n",
      "\t real [gearvr] \t generated: [g]\n",
      "\t real [tbt] \t generated: []\n",
      "\t real [tbt] \t generated: []\n",
      "\t real [tbt] \t generated: []\n",
      "\t real [worldtbday] \t generated: [be2cmai]\n",
      "\t real [worldtbday] \t generated: []\n",
      "\t real [worldtbday] \t generated: [tndu]\n",
      "\t real [iwd] \t generated: [sf1niiw]\n",
      "\t real [iwd] \t generated: [rg]\n",
      "\t real [iwd] \t generated: [cnejeivrg]\n",
      "\t real [ama] \t generated: []\n",
      "\t real [ama] \t generated: [e4doa]\n",
      "\t real [ama] \t generated: []\n",
      "\t real [tbt] \t generated: [ybkubchyc]\n",
      "\t real [tbt] \t generated: [b]\n",
      "\t real [tbt] \t generated: [hsprtpo]\n",
      "\t real [dataviz] \t generated: [o]\n",
      "\t real [dataviz] \t generated: [glwnhestegw]\n",
      "\t real [dataviz] \t generated: [rt1mslh]\n",
      "\t real [mlkday] \t generated: []\n",
      "\t real [mlkday] \t generated: [pstafwabmbr2lb1vehhoffxdtu4tjyixc4ae2on]\n",
      "\t real [mlkday] \t generated: [cfnnr2m0w]\n",
      "\t real [cleanenergy] \t generated: [c0eoovg]\n",
      "\t real [cleanenergy] \t generated: [xnefyclputgf]\n",
      "\t real [cleanenergy] \t generated: []\n",
      "\t real [hourofcode] \t generated: [9cmecfmy]\n",
      "\t real [hourofcode] \t generated: [dovcswj]\n",
      "\t real [hourofcode] \t generated: [rjf2aa]\n",
      "\t real [givingtuesday] \t generated: [mwcuf2abmlhztpumgnboea]\n",
      "\t real [givingtuesday] \t generated: [w]\n",
      "\t real [givingtuesday] \t generated: [m]\n",
      "\t real [longreads] \t generated: []\n",
      "\t real [longreads] \t generated: []\n",
      "\t real [longreads] \t generated: [sb]\n",
      "\t real [unga] \t generated: [ica]\n",
      "\t real [unga] \t generated: [enlhtggynwnosh]\n",
      "\t real [unga] \t generated: [roe2si]\n",
      "\t real [vr] \t generated: [mnp]\n",
      "\t real [vr] \t generated: [fkmr]\n",
      "\t real [vr] \t generated: [twb4w1t]\n",
      "\t real [mosquitoday] \t generated: []\n",
      "\t real [mosquitoday] \t generated: [yoo2uaxc]\n",
      "\t real [mosquitoday] \t generated: [bm]\n",
      "\t real [dataviz] \t generated: [2behiit5madypwa2n]\n",
      "\t real [dataviz] \t generated: [rioftycfftnz]\n",
      "\t real [dataviz] \t generated: [dbeg1t]\n",
      "\t real [nationalbookloversday] \t generated: [hxotdjsoeadb]\n",
      "\t real [nationalbookloversday] \t generated: [oorm4behaidjmc]\n",
      "\t real [nationalbookloversday] \t generated: [yooa]\n",
      "\t real [aids2016] \t generated: [ds]\n",
      "\t real [aids2016] \t generated: [psc3nxyiwdlwjpnmjodd]\n",
      "\t real [aids2016] \t generated: [ton1ylwgtg]\n",
      "\t real [nmal2016] \t generated: [iogn1]\n",
      "\t real [nmal2016] \t generated: [xt5]\n",
      "\t real [nmal2016] \t generated: [tswean]\n",
      "\t real [tbt] \t generated: [mr]\n",
      "\t real [tbt] \t generated: [rcyhi2ftrcancfoolstwahf]\n",
      "\t real [tbt] \t generated: [qaccfnbseofodcbmso2nyscf2]\n",
      "\t real [vr] \t generated: [aatwii]\n",
      "\t real [vr] \t generated: [otrbmeonizk]\n",
      "\t real [vr] \t generated: [vsnt0oetczcx5p9h4h2r1ei]\n",
      "\t real [endmalaria] \t generated: [to]\n",
      "\t real [endmalaria] \t generated: [tneo]\n",
      "\t real [endmalaria] \t generated: [adnt]\n",
      "\t real [weekendread] \t generated: [msiri]\n",
      "\t real [weekendread] \t generated: [beem]\n",
      "\t real [weekendread] \t generated: [wmks]\n",
      "\t real [stateofwomen] \t generated: []\n",
      "\t real [stateofwomen] \t generated: [bmfctwrttotoeashr2cr]\n",
      "\t real [stateofwomen] \t generated: [yijegiaxul1c22f]\n",
      "\t real [rednoseday] \t generated: [tgovtiooaocoa]\n",
      "\t real [rednoseday] \t generated: [ozhpaisgy]\n",
      "\t real [rednoseday] \t generated: [kges]\n",
      "\t real [vr] \t generated: []\n",
      "\t real [vr] \t generated: [ufk2osdynaedryui]\n",
      "\t real [vr] \t generated: [mtyddeqh]\n",
      "\t real [dataviz] \t generated: [gpv]\n",
      "\t real [dataviz] \t generated: [brbkoepdotso]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a3b508f82c0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mnext_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1572\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/user/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1200\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "S = np.zeros((len(sentences), 3))\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    #if i%10==0:\n",
    "    #    print i, \n",
    "    \n",
    "    realht = content[i][end[i]:]\n",
    "    \n",
    "    for j, diversity in enumerate([1.0, 1.3, 1.5]):\n",
    "        \n",
    "        sentence = content[i][:end[i]+1]\n",
    "        genword = '['\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            genword += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            if (next_char==']'):\n",
    "                break\n",
    "                \n",
    "        S[i,j] = similar(genword, realht)\n",
    "        print \"\\t real\", realht, \"\\t generated:\", genword\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "(10000, 3)\n"
     ]
    }
   ],
   "source": [
    "print np.max(S)\n",
    "print S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('similarityM', S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('diversity:', 0.2)\n",
      "real hashtag: [dataviz]\n",
      "generated hashtag: []\n",
      "\n",
      "('diversity:', 0.5)\n",
      "real hashtag: [dataviz]\n",
      "generated hashtag: []\n",
      "\n",
      "('diversity:', 1.0)\n",
      "real hashtag: [dataviz]\n",
      "generated hashtag: []\n",
      "\n",
      "('diversity:', 1.3)\n",
      "real hashtag: [dataviz]\n",
      "generated hashtag: [arfxe]\n",
      "\n",
      "('diversity:', 1.5)\n",
      "real hashtag: [dataviz]\n",
      "generated hashtag: [nsfx5zsosdvpg]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tn = 6\n",
    "for diversity in [0.2, 0.5, 1.0, 1.3, 1.5]:\n",
    "    print('diversity:', diversity)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = content[tn][:end[tn]+1]#text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    generated += '['\n",
    "    #print 'Generating with seed:\\n\"' + sentence[:] +'\"'\n",
    "    print 'real hashtag: ' + content[tn][end[tn]:]\n",
    "    #print 'generated hashtag: ['\n",
    "    #sys.stdout.write(generated+'\\n[')\n",
    "    sys.stdout.write('generated hashtag: [')\n",
    "    \n",
    "    for i in range(400):\n",
    "        x = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        if (next_char==']'):\n",
    "            break\n",
    "        \n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
